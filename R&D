Okay, here's a simplified summary of the research on sticky sessions and caching alternatives:
Sticky Sessions Explained
Sticky sessions (or session affinity) aim to ensure that a user's requests are consistently sent to the same backend server during their active session. This is important for applications that store user-specific information (like items in a shopping cart) on a particular server. [1, 2, 3]
Here are the common approaches:
 * Cookie-Based (Load Balancer Creates Cookie)
   * How it works: The load balancer adds a special cookie to the user's first response. The user's browser then includes this cookie in all future requests, allowing the load balancer to route them back to the original server. [2, 4, 5]
   * Pros:
     * Simple for your application to implement as the load balancer handles the cookie. [6]
     * Reliable even if the user's IP address changes.
   * Cons:
     * Depends on the user's browser supporting and sending cookies.
     * Adds a small amount of data (the cookie) to each request.
 * Cookie-Based (Application Creates Cookie)
   * How it works: Your application creates and manages its own session cookie. The load balancer is configured to read this specific cookie to maintain stickiness. [4, 5, 6]
   * Pros:
     * Gives your application more control over the session and when stickiness should apply or end. [6, 7]
     * Reliable even if the user's IP address changes.
   * Cons:
     * Requires changes to your application's code to generate and manage the cookie.
     * Also depends on browser cookie support.
 * IP-Based (Using User's IP Address)
   * How it works: The load balancer uses the client's IP address to decide which server to send requests to. [3, 8, 9, 10]
   * Pros:
     * Relatively simple to set up.
     * Doesn't require cookies.
   * Cons:
     * Can be unreliable if multiple users share the same public IP address (e.g., users in an office or behind a NAT). [3]
     * Stickiness breaks if the user's IP address changes during their session (common for mobile users).
 * HTTP Header-Based
   * How it works: The load balancer uses a specific HTTP header (e.g., a custom session ID) sent by the client to route requests. [11, 12]
   * Pros:
     * Flexible, especially for non-browser clients like mobile apps or other services (APIs). [11]
     * Allows the application to define routing cues within the headers.
   * Cons:
     * Requires the client application or an intermediary proxy to consistently send the correct HTTP header.
     * Not a standard behavior for web browsers; usually needs custom client-side logic.
 * Consistent Hashing (Advanced)
   * How it works: Uses a mathematical formula (hash) based on request details (like a header, cookie, or IP) to pick a server. It's designed to minimize disruptions when servers are added or removed from the pool. [12]
   * Pros:
     * More resilient to changes in the number of backend servers compared to simple IP hashing (fewer users lose their session). [12]
     * Provides "soft" affinity, attempting to keep users on the same server.
   * Cons:
     * Stickiness is not absolutely guaranteed; sessions can still be lost if the server pool changes significantly. [12]
     * Can be more complex to configure.
 * Stateful Session Filters (Advanced, e.g., in Istio/Envoy)
   * How it works: A specialized filter directly maps a client to a specific backend server based on a unique identifier (in a header or cookie), overriding standard load balancing for subsequent requests from that client. [12]
   * Pros:
     * Provides very strong and deterministic session affinity.
   * Cons:
     * The client application must be able to receive, store, and resend the session identifier with every request. [12]
     * Can lead to uneven load distribution if many "sticky" clients land on one server, and has potential security concerns if not carefully managed. [12]
Caching Alternatives Explained
Caching involves storing frequently accessed data temporarily in a faster storage location to speed up access and reduce the load on primary systems. [13, 14]
Here are some alternatives to a single, centralized cache:
 * Distributed Cache
   * How it works: Data is spread across multiple interconnected computers (nodes), which work together as a single, large cache. [15, 16, 17, 18]
   * Pros:
     * Highly scalable; you can add more machines to increase capacity and performance. [16, 17, 13]
     * Good for storing shared data (like user sessions) and offers high availability (data is often replicated across nodes). [16, 17]
   * Cons:
     * More complex to set up, manage, and monitor than simpler caching methods. [16]
     * Accessing data involves network communication, which is slower than accessing local memory. [16]
 * Per-Instance In-Memory Cache (Local Cache)
   * How it works: Each individual application server stores its own cached data directly in its own memory. [16, 19, 14]
   * Pros:
     * Extremely fast access because data is in local memory (no network calls). [16, 14]
     * Relatively simple to implement. [16]
   * Cons:
     * Cache size is limited by the memory available on each individual server. [16, 14]
     * If cached data is shared and changes, it can become inconsistent across different servers. [16, 19]
     * The entire cache for an instance is lost if that server restarts. [16]
 * Client-Side Caching (e.g., Browser Cache)
   * How it works: The user's web browser (or other client device) stores copies of web resources like images, stylesheets (CSS), JavaScript files, and even API responses locally. [20, 21]
   * Pros:
     * Dramatically improves load times and perceived performance for users on repeat visits. [20]
     * Reduces the load on your servers and saves bandwidth costs. [20, 21]
   * Cons:
     * Users might see outdated (stale) content if caching rules and updates are not managed carefully. [20]
     * The cache is local to a single user and their specific browser; it doesn't benefit first-time visitors or other users.
 * Edge Caching (Content Delivery Networks - CDNs)
   * How it works: Copies of your website's content (especially static files like images, videos, and scripts) are stored on a network of servers geographically distributed around the world (called edge servers). Users are served content from the edge server closest to them. [22, 23, 24]
   * Pros:
     * Significantly reduces latency (delay) and speeds up content delivery for users globally. [22, 23]
     * Reduces the load on your main (origin) server by handling many requests at the "edge." [22, 23]
   * Cons:
     * Primarily optimized for static or infrequently changing content; caching highly dynamic content is more complex. [24]
     * CDN services have associated costs.
     * When content is updated on your origin server, there can be a delay (invalidation latency) before it's refreshed across all edge servers.
